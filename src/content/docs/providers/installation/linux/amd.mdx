---
title: 'Linux AMD Setup'
description: Install GPUFlow on Linux systems with AMD GPUs using Docker or Podman.
sidebar:
    label: 'Linux + AMD'
    order: 5
---
{/* File: providers/installation/linux/amd.mdx */}

import { Aside } from '@astrojs/starlight/components';

This guide covers Linux systems with AMD GPUs. AMD GPU support uses ROCm (Radeon Open Compute) for container access.

<Aside type="caution">
AMD GPU support is currently experimental. NVIDIA GPUs have more mature tooling and broader software support.
</Aside>

## Prerequisites

- AMD RX 6000 series or newer GPU
- Ubuntu 22.04+ or Fedora 39+
- At least 16GB system RAM

## Step 1: Check GPU compatibility

Verify your AMD GPU is detected:

```bash
lspci | grep -i amd
```

Supported AMD GPUs for GPUFlow:
- RX 6600, 6700, 6800, 6900 series
- RX 7600, 7700, 7800, 7900 series
- Radeon Pro W6000+ series

## Step 2: Install AMD drivers

Install the AMD GPU drivers:

```bash
# Ubuntu/Debian
wget https://repo.radeon.com/amdgpu-install/22.40.5/ubuntu/jammy/amdgpu-install_5.4.50405-1_all.deb
sudo dpkg -i amdgpu-install_5.4.50405-1_all.deb
sudo apt update
sudo amdgpu-install --usecase=dkms,graphics,rocm

# Fedora
sudo dnf install https://repo.radeon.com/amdgpu-install/22.40.5/rhel/9.1/amdgpu-install-5.4.50405-1.el9.noarch.rpm
sudo amdgpu-install --usecase=dkms,graphics,rocm
```

Add your user to the render group:

```bash
sudo usermod -a -G render $USER
sudo usermod -a -G video $USER
```

Log out and back in for group changes to take effect.

## Step 3: Verify ROCm installation

Test that ROCm can see your GPU:

```bash
rocm-smi

# Should show your AMD GPU with temperature, usage, etc.
```

If `rocm-smi` is not found, install ROCm separately:

```bash
# Ubuntu
sudo apt install rocm-smi-lib

# Fedora  
sudo dnf install rocm-smi
```

## Step 4: Choose container runtime

Select either Docker or Podman for running containers:

<div class="grid grid-cols-1 md:grid-cols-2 gap-4">
  <div class="border rounded-lg p-4">
    <h4>Docker + AMD</h4>
    <p>Standard Docker with ROCm container support</p>
    <a href="/providers/container-runtime/docker-amd">Continue with Docker →</a>
  </div>
  
  <div class="border rounded-lg p-4">
    <h4>Podman + AMD</h4>
    <p>Rootless containers with ROCm integration</p>
    <a href="/providers/container-runtime/podman-amd">Continue with Podman →</a>
  </div>
</div>

## Known limitations

AMD GPU support has some current limitations:

- **Software compatibility**: Fewer ML frameworks support ROCm compared to CUDA
- **Performance**: May be slower than equivalent NVIDIA GPUs for AI workloads  
- **Container ecosystem**: Limited pre-built containers with ROCm support
- **Stability**: ROCm drivers can be less stable than NVIDIA's mature CUDA stack

## What's next

After completing container runtime setup:

1. Deploy GPUFlow provider with AMD GPU passthrough
2. [Create your provider account](/providers/configuration/account-setup)  
3. [Configure GPU listings](/providers/configuration/creating-listings) with AMD-specific notes

<Aside type="note">
AMD GPUs work well for compute workloads and crypto mining. AI/ML performance varies by framework and model.
</Aside>
